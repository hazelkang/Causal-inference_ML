{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"real_Finedust_threshold50_ satisfaction1.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOP3StFOgxa22xYP5dXfrss"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"227ksGb1mu8C","executionInfo":{"status":"ok","timestamp":1601375586236,"user_tz":-540,"elapsed":3665,"user":{"displayName":"Hazel Kang","photoUrl":"","userId":"09199737328986746816"}},"outputId":"385040a2-2813-411c-9568-bb106204e471","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["pip install qeds fiona geopandas xgboost gensim folium pyLDAvis descartes statspy "],"execution_count":80,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: qeds in /usr/local/lib/python3.6/dist-packages (0.6.2)\n","Requirement already satisfied: fiona in /usr/local/lib/python3.6/dist-packages (1.8.17)\n","Requirement already satisfied: geopandas in /usr/local/lib/python3.6/dist-packages (0.8.1)\n","Requirement already satisfied: xgboost in /usr/local/lib/python3.6/dist-packages (0.90)\n","Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n","Requirement already satisfied: folium in /usr/local/lib/python3.6/dist-packages (0.8.3)\n","Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.6/dist-packages (2.1.2)\n","Requirement already satisfied: descartes in /usr/local/lib/python3.6/dist-packages (1.1.0)\n","Requirement already satisfied: statspy in /usr/local/lib/python3.6/dist-packages (0.1.0a1)\n","Requirement already satisfied: quantecon in /usr/local/lib/python3.6/dist-packages (from qeds) (0.4.8)\n","Requirement already satisfied: quandl in /usr/local/lib/python3.6/dist-packages (from qeds) (3.5.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from qeds) (1.18.5)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from qeds) (1.0.5)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from qeds) (4.4.1)\n","Requirement already satisfied: pyarrow in /usr/local/lib/python3.6/dist-packages (from qeds) (0.14.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from qeds) (2.23.0)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from qeds) (0.10.1)\n","Requirement already satisfied: openpyxl in /usr/local/lib/python3.6/dist-packages (from qeds) (2.5.9)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from qeds) (1.4.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from qeds) (3.2.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from qeds) (0.22.2.post1)\n","Requirement already satisfied: statsmodels in /usr/local/lib/python3.6/dist-packages (from qeds) (0.10.2)\n","Requirement already satisfied: pandas-datareader in /usr/local/lib/python3.6/dist-packages (from qeds) (0.8.1)\n","Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.6/dist-packages (from fiona) (20.2.0)\n","Requirement already satisfied: munch in /usr/local/lib/python3.6/dist-packages (from fiona) (2.5.0)\n","Requirement already satisfied: click<8,>=4.0 in /usr/local/lib/python3.6/dist-packages (from fiona) (7.1.2)\n","Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.6/dist-packages (from fiona) (1.1.1)\n","Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.6/dist-packages (from fiona) (1.15.0)\n","Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.6/dist-packages (from fiona) (0.5.0)\n","Requirement already satisfied: pyproj>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from geopandas) (2.6.1.post1)\n","Requirement already satisfied: shapely in /usr/local/lib/python3.6/dist-packages (from geopandas) (1.7.1)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (2.1.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from folium) (2.11.2)\n","Requirement already satisfied: branca>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from folium) (0.4.1)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (0.16.0)\n","Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (3.6.4)\n","Requirement already satisfied: joblib>=0.8.4 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (0.16.0)\n","Requirement already satisfied: wheel>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (0.35.1)\n","Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (2.7.1)\n","Requirement already satisfied: funcy in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (1.15)\n","Requirement already satisfied: numba>=0.38 in /usr/local/lib/python3.6/dist-packages (from quantecon->qeds) (0.48.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.6/dist-packages (from quantecon->qeds) (1.1.1)\n","Requirement already satisfied: more-itertools in /usr/local/lib/python3.6/dist-packages (from quandl->qeds) (8.5.0)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from quandl->qeds) (2.8.1)\n","Requirement already satisfied: inflection>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from quandl->qeds) (0.5.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->qeds) (2018.9)\n","Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->qeds) (1.3.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->qeds) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->qeds) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->qeds) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->qeds) (2020.6.20)\n","Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.6/dist-packages (from openpyxl->qeds) (1.0.1)\n","Requirement already satisfied: jdcal in /usr/local/lib/python3.6/dist-packages (from openpyxl->qeds) (1.4.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->qeds) (2.4.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->qeds) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->qeds) (0.10.0)\n","Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from statsmodels->qeds) (0.5.1)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from pandas-datareader->qeds) (4.2.6)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.14.63)\n","Requirement already satisfied: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->folium) (1.1.1)\n","Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (0.7.1)\n","Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (1.4.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (50.3.0)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (1.9.0)\n","Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38->quantecon->qeds) (0.31.0)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.6/dist-packages (from sympy->quantecon->qeds) (1.1.0)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.10.0)\n","Requirement already satisfied: botocore<1.18.0,>=1.17.63 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.17.63)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.3.3)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.63->boto3->smart-open>=1.2.1->gensim) (0.15.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AX61rOSdm7Ll","executionInfo":{"status":"ok","timestamp":1601375586238,"user_tz":-540,"elapsed":3601,"user":{"displayName":"Hazel Kang","photoUrl":"","userId":"09199737328986746816"}}},"source":["#Import\n","import pandas as pd\n","import numpy as np\n","import patsy\n","import statspy as sp\n","from sklearn import linear_model, ensemble, base, neural_network\n","#\n","import statsmodels.formula.api as smf\n","import statsmodels.api as sm\n","from sklearn.utils.testing import ignore_warnings\n","from sklearn.exceptions import ConvergenceWarning\n","\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","import seaborn as sns"],"execution_count":81,"outputs":[]},{"cell_type":"code","metadata":{"id":"aqbs7IQeoMHv","executionInfo":{"status":"ok","timestamp":1601375588212,"user_tz":-540,"elapsed":5532,"user":{"displayName":"Hazel Kang","photoUrl":"","userId":"09199737328986746816"}},"outputId":"23037c1a-ca14-4009-8088-a88d2e540218","colab":{"base_uri":"https://localhost:8080/","height":349}},"source":["#Load file - Demeaned by Location\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","df_path=\"/content/drive/My Drive/ML/KCYPS2010-m1e4e1_new.dta\"\n","df=pd.read_stata(df_path)\n","df.describe()"],"execution_count":82,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>year</th>\n","      <th>panel</th>\n","      <th>gender</th>\n","      <th>age</th>\n","      <th>school_loc</th>\n","      <th>ind_loc</th>\n","      <th>school</th>\n","      <th>grade</th>\n","      <th>coeduw</th>\n","      <th>f_edu</th>\n","      <th>m_edu</th>\n","      <th>health</th>\n","      <th>exercise_time</th>\n","      <th>ego_resilience1</th>\n","      <th>ego_resilience2</th>\n","      <th>ego_resilience3</th>\n","      <th>ego_resilience4</th>\n","      <th>ego_resilience5</th>\n","      <th>ego_resilience6</th>\n","      <th>ego_resilience7</th>\n","      <th>ego_resilience8</th>\n","      <th>ego_resilience9</th>\n","      <th>ego_resilience10</th>\n","      <th>ego_resilience11</th>\n","      <th>ego_resilience12</th>\n","      <th>ego_resilience13</th>\n","      <th>ego_resilience14</th>\n","      <th>satisfaction1</th>\n","      <th>satisfaction2</th>\n","      <th>satisfaction3</th>\n","      <th>homework1_time1</th>\n","      <th>homework1_time2</th>\n","      <th>homework1_time3</th>\n","      <th>homework1_time4</th>\n","      <th>homework2_time1</th>\n","      <th>homework2_time2</th>\n","      <th>homework2_time3</th>\n","      <th>homework2_time4</th>\n","      <th>homework3_time1</th>\n","      <th>...</th>\n","      <th>temp_min_n</th>\n","      <th>temp_min</th>\n","      <th>temp_max_n</th>\n","      <th>temp_max</th>\n","      <th>rainfall_n</th>\n","      <th>rainfall</th>\n","      <th>wind_max_n</th>\n","      <th>wind_max</th>\n","      <th>wind_avg_n</th>\n","      <th>wind_avg</th>\n","      <th>m_study</th>\n","      <th>f_study</th>\n","      <th>female</th>\n","      <th>exercise_time1</th>\n","      <th>loc_yr</th>\n","      <th>hwtime_schday</th>\n","      <th>hwtime_nonschday</th>\n","      <th>withfriend_time_sch</th>\n","      <th>withfriend_time_nsch</th>\n","      <th>satisfaction</th>\n","      <th>aggressive</th>\n","      <th>symptom_phy</th>\n","      <th>depression</th>\n","      <th>ego_resilience</th>\n","      <th>social_cohesion</th>\n","      <th>move</th>\n","      <th>income</th>\n","      <th>aggressive_p1</th>\n","      <th>depression_p1</th>\n","      <th>symptom_phy_p1</th>\n","      <th>ego_resilience_p1</th>\n","      <th>aggressive_p2</th>\n","      <th>depression_p2</th>\n","      <th>symptom_phy_p2</th>\n","      <th>ego_resilience_p2</th>\n","      <th>satisfaction_p3</th>\n","      <th>aggressive_p3</th>\n","      <th>depression_p3</th>\n","      <th>symptom_phy_p3</th>\n","      <th>ego_resilience_p3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>25468.000000</td>\n","      <td>25468.000000</td>\n","      <td>25468.000000</td>\n","      <td>25013.000000</td>\n","      <td>25093.000000</td>\n","      <td>19490.000000</td>\n","      <td>25468.000000</td>\n","      <td>25010.000000</td>\n","      <td>25033.000000</td>\n","      <td>13073.000000</td>\n","      <td>24328.000000</td>\n","      <td>24536.000000</td>\n","      <td>25004.000000</td>\n","      <td>25008.000000</td>\n","      <td>13182.000000</td>\n","      <td>13181.000000</td>\n","      <td>13182.000000</td>\n","      <td>13182.000000</td>\n","      <td>13181.000000</td>\n","      <td>13182.000000</td>\n","      <td>13182.000000</td>\n","      <td>13182.000000</td>\n","      <td>13182.000000</td>\n","      <td>13181.000000</td>\n","      <td>13181.000000</td>\n","      <td>13181.000000</td>\n","      <td>13181.000000</td>\n","      <td>13180.000000</td>\n","      <td>23472.000000</td>\n","      <td>23474.000000</td>\n","      <td>23474.000000</td>\n","      <td>24832.000000</td>\n","      <td>24832.000000</td>\n","      <td>24880.000000</td>\n","      <td>24880.000000</td>\n","      <td>24778.000000</td>\n","      <td>24778.000000</td>\n","      <td>24802.000000</td>\n","      <td>24802.000000</td>\n","      <td>24884.000000</td>\n","      <td>...</td>\n","      <td>24891.000000</td>\n","      <td>24891.000000</td>\n","      <td>24891.000000</td>\n","      <td>24891.000000</td>\n","      <td>24891.000000</td>\n","      <td>24891.000000</td>\n","      <td>24891.000000</td>\n","      <td>24891.000000</td>\n","      <td>24891.000000</td>\n","      <td>24891.000000</td>\n","      <td>25468.000000</td>\n","      <td>25468.000000</td>\n","      <td>25468.000000</td>\n","      <td>25008.000000</td>\n","      <td>25468.000000</td>\n","      <td>24607.000000</td>\n","      <td>24686.000000</td>\n","      <td>24866.000000</td>\n","      <td>24891.000000</td>\n","      <td>23569.000000</td>\n","      <td>16308.000000</td>\n","      <td>16308.000000</td>\n","      <td>16308.000000</td>\n","      <td>13460.000000</td>\n","      <td>24993.000000</td>\n","      <td>25468.000000</td>\n","      <td>25468.000000</td>\n","      <td>25468.000000</td>\n","      <td>25468.000000</td>\n","      <td>25468.000000</td>\n","      <td>25468.000000</td>\n","      <td>25468.000000</td>\n","      <td>25468.000000</td>\n","      <td>25468.000000</td>\n","      <td>25468.000000</td>\n","      <td>25468.000000</td>\n","      <td>25468.000000</td>\n","      <td>25468.000000</td>\n","      <td>25468.000000</td>\n","      <td>25468.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>87913.105623</td>\n","      <td>2012.853760</td>\n","      <td>2.117952</td>\n","      <td>1.467397</td>\n","      <td>13.397601</td>\n","      <td>2741.557414</td>\n","      <td>2746.313570</td>\n","      <td>1.862015</td>\n","      <td>2.972636</td>\n","      <td>2.451771</td>\n","      <td>2.884865</td>\n","      <td>2.698769</td>\n","      <td>3.281715</td>\n","      <td>2.913988</td>\n","      <td>3.074040</td>\n","      <td>3.036871</td>\n","      <td>3.082385</td>\n","      <td>3.043013</td>\n","      <td>2.948866</td>\n","      <td>3.035958</td>\n","      <td>2.682749</td>\n","      <td>2.949325</td>\n","      <td>2.829237</td>\n","      <td>3.037933</td>\n","      <td>2.803657</td>\n","      <td>2.780821</td>\n","      <td>2.958197</td>\n","      <td>3.173976</td>\n","      <td>3.287960</td>\n","      <td>2.791088</td>\n","      <td>3.238434</td>\n","      <td>0.427150</td>\n","      <td>12.297922</td>\n","      <td>0.427653</td>\n","      <td>8.462379</td>\n","      <td>0.483857</td>\n","      <td>8.254702</td>\n","      <td>0.473430</td>\n","      <td>5.805338</td>\n","      <td>0.847452</td>\n","      <td>...</td>\n","      <td>7.308627</td>\n","      <td>3.960305</td>\n","      <td>16.920568</td>\n","      <td>13.723699</td>\n","      <td>3.196835</td>\n","      <td>1.948080</td>\n","      <td>7.116713</td>\n","      <td>7.314519</td>\n","      <td>1.811941</td>\n","      <td>1.880025</td>\n","      <td>13.040051</td>\n","      <td>13.441613</td>\n","      <td>0.459047</td>\n","      <td>1.913988</td>\n","      <td>272.760803</td>\n","      <td>2.211384</td>\n","      <td>2.227036</td>\n","      <td>0.841032</td>\n","      <td>2.089274</td>\n","      <td>0.001044</td>\n","      <td>-0.000357</td>\n","      <td>-0.000072</td>\n","      <td>-0.001104</td>\n","      <td>0.001772</td>\n","      <td>0.000948</td>\n","      <td>0.072444</td>\n","      <td>4.713395</td>\n","      <td>0.000290</td>\n","      <td>-0.000158</td>\n","      <td>0.000303</td>\n","      <td>0.000600</td>\n","      <td>0.000287</td>\n","      <td>-0.000162</td>\n","      <td>0.000298</td>\n","      <td>0.000604</td>\n","      <td>0.000726</td>\n","      <td>0.000284</td>\n","      <td>-0.000162</td>\n","      <td>0.000298</td>\n","      <td>0.000603</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>50006.514034</td>\n","      <td>1.921218</td>\n","      <td>0.757773</td>\n","      <td>0.498946</td>\n","      <td>2.308522</td>\n","      <td>894.825103</td>\n","      <td>895.389902</td>\n","      <td>0.762092</td>\n","      <td>1.736361</td>\n","      <td>0.780727</td>\n","      <td>1.789775</td>\n","      <td>1.580844</td>\n","      <td>0.593584</td>\n","      <td>1.264765</td>\n","      <td>0.650978</td>\n","      <td>0.696299</td>\n","      <td>0.771551</td>\n","      <td>0.659711</td>\n","      <td>0.868586</td>\n","      <td>0.752759</td>\n","      <td>0.917145</td>\n","      <td>0.789322</td>\n","      <td>0.789537</td>\n","      <td>0.768452</td>\n","      <td>0.811332</td>\n","      <td>0.810767</td>\n","      <td>0.776063</td>\n","      <td>0.686779</td>\n","      <td>0.682429</td>\n","      <td>0.883672</td>\n","      <td>0.724015</td>\n","      <td>0.655464</td>\n","      <td>14.657259</td>\n","      <td>0.743685</td>\n","      <td>13.559300</td>\n","      <td>0.749488</td>\n","      <td>13.700982</td>\n","      <td>0.851854</td>\n","      <td>12.110255</td>\n","      <td>1.186044</td>\n","      <td>...</td>\n","      <td>3.089340</td>\n","      <td>3.432631</td>\n","      <td>2.439558</td>\n","      <td>2.750279</td>\n","      <td>4.701747</td>\n","      <td>3.439408</td>\n","      <td>2.055955</td>\n","      <td>2.171004</td>\n","      <td>0.962986</td>\n","      <td>1.027465</td>\n","      <td>3.835263</td>\n","      <td>4.485485</td>\n","      <td>0.498330</td>\n","      <td>1.264866</td>\n","      <td>147.699905</td>\n","      <td>1.630425</td>\n","      <td>2.155110</td>\n","      <td>1.047577</td>\n","      <td>2.007680</td>\n","      <td>0.890658</td>\n","      <td>0.890302</td>\n","      <td>0.914353</td>\n","      <td>0.940720</td>\n","      <td>0.926650</td>\n","      <td>0.890123</td>\n","      <td>0.259226</td>\n","      <td>2.632188</td>\n","      <td>0.047453</td>\n","      <td>0.058434</td>\n","      <td>0.045313</td>\n","      <td>0.070305</td>\n","      <td>0.047391</td>\n","      <td>0.058327</td>\n","      <td>0.045203</td>\n","      <td>0.070110</td>\n","      <td>0.055151</td>\n","      <td>0.047342</td>\n","      <td>0.058376</td>\n","      <td>0.045279</td>\n","      <td>0.070275</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>14201.000000</td>\n","      <td>2010.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>9.000000</td>\n","      <td>-9.000000</td>\n","      <td>1001.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>-9.000000</td>\n","      <td>-9.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>-0.983333</td>\n","      <td>-5.644444</td>\n","      <td>10.175000</td>\n","      <td>5.533333</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>2.775000</td>\n","      <td>2.666667</td>\n","      <td>0.300000</td>\n","      <td>0.266667</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>-3.785720</td>\n","      <td>-1.666522</td>\n","      <td>-1.472274</td>\n","      <td>-1.418390</td>\n","      <td>-4.065019</td>\n","      <td>-3.225905</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>-0.208596</td>\n","      <td>-0.488187</td>\n","      <td>-0.119528</td>\n","      <td>-0.230438</td>\n","      <td>-0.207695</td>\n","      <td>-0.486564</td>\n","      <td>-0.119638</td>\n","      <td>-0.230012</td>\n","      <td>-0.185863</td>\n","      <td>-0.204904</td>\n","      <td>-0.485205</td>\n","      <td>-0.119977</td>\n","      <td>-0.230675</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>45732.000000</td>\n","      <td>2012.000000</td>\n","      <td>2.000000</td>\n","      <td>1.000000</td>\n","      <td>12.000000</td>\n","      <td>2206.000000</td>\n","      <td>2206.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>2.000000</td>\n","      <td>2.000000</td>\n","      <td>2.000000</td>\n","      <td>3.000000</td>\n","      <td>2.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>2.000000</td>\n","      <td>3.000000</td>\n","      <td>2.000000</td>\n","      <td>2.000000</td>\n","      <td>2.000000</td>\n","      <td>3.000000</td>\n","      <td>2.000000</td>\n","      <td>2.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>2.000000</td>\n","      <td>3.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>5.125000</td>\n","      <td>1.433333</td>\n","      <td>15.268749</td>\n","      <td>12.033333</td>\n","      <td>0.250000</td>\n","      <td>0.000000</td>\n","      <td>5.650000</td>\n","      <td>5.766666</td>\n","      <td>1.120000</td>\n","      <td>1.116667</td>\n","      <td>12.000000</td>\n","      <td>12.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>158.750000</td>\n","      <td>1.000000</td>\n","      <td>0.500000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>-0.516459</td>\n","      <td>-0.679248</td>\n","      <td>-0.811554</td>\n","      <td>-0.832235</td>\n","      <td>-0.600126</td>\n","      <td>-0.532953</td>\n","      <td>0.000000</td>\n","      <td>3.000000</td>\n","      <td>-0.030510</td>\n","      <td>-0.032831</td>\n","      <td>-0.032709</td>\n","      <td>-0.031780</td>\n","      <td>-0.030423</td>\n","      <td>-0.032738</td>\n","      <td>-0.032433</td>\n","      <td>-0.031676</td>\n","      <td>-0.024723</td>\n","      <td>-0.030508</td>\n","      <td>-0.032835</td>\n","      <td>-0.032488</td>\n","      <td>-0.031734</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>81607.000000</td>\n","      <td>2013.000000</td>\n","      <td>2.000000</td>\n","      <td>1.000000</td>\n","      <td>13.000000</td>\n","      <td>3023.000000</td>\n","      <td>3023.000000</td>\n","      <td>2.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>2.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>7.144444</td>\n","      <td>3.816667</td>\n","      <td>16.887501</td>\n","      <td>13.650000</td>\n","      <td>1.375000</td>\n","      <td>0.687500</td>\n","      <td>6.775000</td>\n","      <td>6.966667</td>\n","      <td>1.525000</td>\n","      <td>1.566667</td>\n","      <td>12.000000</td>\n","      <td>14.000000</td>\n","      <td>0.000000</td>\n","      <td>2.000000</td>\n","      <td>277.000000</td>\n","      <td>2.000000</td>\n","      <td>2.000000</td>\n","      <td>0.500000</td>\n","      <td>2.000000</td>\n","      <td>-0.041861</td>\n","      <td>0.030267</td>\n","      <td>0.031921</td>\n","      <td>-0.019926</td>\n","      <td>-0.063517</td>\n","      <td>-0.057264</td>\n","      <td>0.000000</td>\n","      <td>4.500000</td>\n","      <td>-0.001802</td>\n","      <td>-0.003242</td>\n","      <td>0.000212</td>\n","      <td>0.000638</td>\n","      <td>-0.001856</td>\n","      <td>-0.003303</td>\n","      <td>-0.000026</td>\n","      <td>0.000811</td>\n","      <td>0.001315</td>\n","      <td>-0.001914</td>\n","      <td>-0.003299</td>\n","      <td>-0.000033</td>\n","      <td>0.000997</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>137606.000000</td>\n","      <td>2015.000000</td>\n","      <td>3.000000</td>\n","      <td>2.000000</td>\n","      <td>15.000000</td>\n","      <td>3511.000000</td>\n","      <td>3511.000000</td>\n","      <td>2.000000</td>\n","      <td>4.000000</td>\n","      <td>3.000000</td>\n","      <td>4.000000</td>\n","      <td>4.000000</td>\n","      <td>4.000000</td>\n","      <td>4.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>4.000000</td>\n","      <td>3.000000</td>\n","      <td>4.000000</td>\n","      <td>4.000000</td>\n","      <td>3.000000</td>\n","      <td>4.000000</td>\n","      <td>3.000000</td>\n","      <td>4.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>4.000000</td>\n","      <td>4.000000</td>\n","      <td>3.000000</td>\n","      <td>4.000000</td>\n","      <td>1.000000</td>\n","      <td>30.000000</td>\n","      <td>1.000000</td>\n","      <td>20.000000</td>\n","      <td>1.000000</td>\n","      <td>20.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>9.322222</td>\n","      <td>6.566667</td>\n","      <td>18.299999</td>\n","      <td>15.500000</td>\n","      <td>4.187500</td>\n","      <td>2.440000</td>\n","      <td>8.368750</td>\n","      <td>8.766666</td>\n","      <td>2.350000</td>\n","      <td>2.433333</td>\n","      <td>16.000000</td>\n","      <td>16.000000</td>\n","      <td>1.000000</td>\n","      <td>3.000000</td>\n","      <td>383.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>1.000000</td>\n","      <td>3.000000</td>\n","      <td>0.848684</td>\n","      <td>0.589594</td>\n","      <td>0.581082</td>\n","      <td>0.593520</td>\n","      <td>0.598297</td>\n","      <td>0.486844</td>\n","      <td>0.000000</td>\n","      <td>6.000000</td>\n","      <td>0.019340</td>\n","      <td>0.025470</td>\n","      <td>0.016221</td>\n","      <td>0.038664</td>\n","      <td>0.019308</td>\n","      <td>0.025405</td>\n","      <td>0.016153</td>\n","      <td>0.038639</td>\n","      <td>0.032263</td>\n","      <td>0.019253</td>\n","      <td>0.025414</td>\n","      <td>0.016180</td>\n","      <td>0.038778</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>168824.000000</td>\n","      <td>2016.000000</td>\n","      <td>3.000000</td>\n","      <td>2.000000</td>\n","      <td>20.000000</td>\n","      <td>3802.000000</td>\n","      <td>3802.000000</td>\n","      <td>7.000000</td>\n","      <td>8.000000</td>\n","      <td>3.000000</td>\n","      <td>6.000000</td>\n","      <td>6.000000</td>\n","      <td>4.000000</td>\n","      <td>5.000000</td>\n","      <td>4.000000</td>\n","      <td>4.000000</td>\n","      <td>4.000000</td>\n","      <td>4.000000</td>\n","      <td>4.000000</td>\n","      <td>4.000000</td>\n","      <td>4.000000</td>\n","      <td>4.000000</td>\n","      <td>4.000000</td>\n","      <td>4.000000</td>\n","      <td>4.000000</td>\n","      <td>4.000000</td>\n","      <td>4.000000</td>\n","      <td>4.000000</td>\n","      <td>4.000000</td>\n","      <td>4.000000</td>\n","      <td>4.000000</td>\n","      <td>8.000000</td>\n","      <td>59.000000</td>\n","      <td>14.000000</td>\n","      <td>59.000000</td>\n","      <td>10.000000</td>\n","      <td>55.000000</td>\n","      <td>12.000000</td>\n","      <td>59.000000</td>\n","      <td>9.000000</td>\n","      <td>...</td>\n","      <td>17.666666</td>\n","      <td>13.966666</td>\n","      <td>26.016666</td>\n","      <td>23.200001</td>\n","      <td>36.500000</td>\n","      <td>43.000000</td>\n","      <td>16.700001</td>\n","      <td>16.566666</td>\n","      <td>5.625000</td>\n","      <td>6.466667</td>\n","      <td>23.000000</td>\n","      <td>23.000000</td>\n","      <td>1.000000</td>\n","      <td>4.000000</td>\n","      <td>575.000000</td>\n","      <td>19.000000</td>\n","      <td>28.000000</td>\n","      <td>10.000000</td>\n","      <td>14.000000</td>\n","      <td>1.427503</td>\n","      <td>3.424091</td>\n","      <td>3.513397</td>\n","      <td>4.216280</td>\n","      <td>2.386542</td>\n","      <td>1.961005</td>\n","      <td>1.000000</td>\n","      <td>60.000000</td>\n","      <td>0.175252</td>\n","      <td>0.192094</td>\n","      <td>0.164869</td>\n","      <td>0.735808</td>\n","      <td>0.174833</td>\n","      <td>0.191582</td>\n","      <td>0.165308</td>\n","      <td>0.732145</td>\n","      <td>0.572267</td>\n","      <td>0.174767</td>\n","      <td>0.191935</td>\n","      <td>0.165799</td>\n","      <td>0.731440</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8 rows × 148 columns</p>\n","</div>"],"text/plain":["                  id          year  ...  symptom_phy_p3  ego_resilience_p3\n","count   25468.000000  25468.000000  ...    25468.000000       25468.000000\n","mean    87913.105623   2012.853760  ...        0.000298           0.000603\n","std     50006.514034      1.921218  ...        0.045279           0.070275\n","min     14201.000000   2010.000000  ...       -0.119977          -0.230675\n","25%     45732.000000   2012.000000  ...       -0.032488          -0.031734\n","50%     81607.000000   2013.000000  ...       -0.000033           0.000997\n","75%    137606.000000   2015.000000  ...        0.016180           0.038778\n","max    168824.000000   2016.000000  ...        0.165799           0.731440\n","\n","[8 rows x 148 columns]"]},"metadata":{"tags":[]},"execution_count":82}]},{"cell_type":"code","metadata":{"id":"AkQEsWS006ja","executionInfo":{"status":"ok","timestamp":1601375588216,"user_tz":-540,"elapsed":5516,"user":{"displayName":"Hazel Kang","photoUrl":"","userId":"09199737328986746816"}}},"source":["## (Outcome1) satisfaction1\n","\n","#satisfaction, health, aggressive, depression\n","\n","#Set dataset/cleaning\n","formula=\"\"\"\n","satisfaction1 ~ pm10_bad + income + age + p_study + temp_avg + rainfall + wind_avg\n","\"\"\"\n","\n","df[\"p_study\"] = ((df[\"m_study\"] >=12)|(df[\"f_study\"] >=12)).astype(int)\n","\n","satisfaction1, X = patsy.dmatrices(formula, df, return_type=\"dataframe\")\n","# some categories are empty after dropping rows will Null, drop now\n","#X = X.loc[:, X.sum() > 0]\n","satisfaction1 = satisfaction1.iloc[:, 0]\n","treatment_variable = \"pm10_bad\"\n","treatment = X[\"pm10_bad\"]\n","Xl = X.drop([\"Intercept\",\"pm10_bad\"], axis=1)\n","loc_id = df.loc[X.index, \"ind_loc\"].astype(\"category\")\n","\n","import re\n","# remove [ ] from names for compatibility with xgboost\n","Xl = Xl.rename(columns=lambda x: re.sub('\\[|\\]','_',x))"],"execution_count":83,"outputs":[]},{"cell_type":"code","metadata":{"id":"euZjVZUpc6mo","executionInfo":{"status":"ok","timestamp":1601378315725,"user_tz":-540,"elapsed":1664,"user":{"displayName":"Hazel Kang","photoUrl":"","userId":"09199737328986746816"}}},"source":["################################################################################\n","\n","##Step 1: Best ML \n","# Def of SE\n","def get_treatment_se(fit, cluster_id, rows=None):\n","    if cluster_id is not None:\n","        if rows is None:\n","            rows = [True] * len(cluster_id)\n","        vcov = sm.stats.sandwich_covariance.cov_cluster(fit, cluster_id.loc[rows])\n","        return np.sqrt(np.diag(vcov))\n","\n","    return fit.HC0_se\n","\n","# Def of Generic ML model\n","def generic_ml_model(x, y, treatment, model, n_split=100, n_group=5, cluster_id=None):\n","    nobs = x.shape[0]\n","\n","    blp = np.zeros((n_split, 2))\n","    blp_se = blp.copy()\n","    blp_ci_l = blp.copy()\n","    blp_ci_u = blp.copy()\n","    blp_pvalue= np.zeros((n_split, 4))\n","\n","    gate = np.zeros((n_split, n_group))\n","    affected = np.zeros((n_split, 3))    \n","    gate_se = affected.copy()\n","    affected_ci_l = affected.copy()\n","    affected_ci_u = affected.copy()\n","    affected_pvalue = np.zeros((n_split, 6))\n","\n","    blp_new = np.zeros((1, 2))\n","    affected_new = np.zeros((1, 3))\n","\n","    baseline = np.zeros((nobs, n_split))\n","    cate = baseline.copy()\n","    lamb = np.zeros((n_split, 2))\n","\n","    for i in range(n_split):\n","        main = np.random.rand(nobs) > 0.5\n","        rows1 = ~main & (treatment == 1)\n","        rows0 = ~main & (treatment == 0)\n","\n","        mod1 = base.clone(model).fit(x.loc[rows1, :], (y.loc[rows1]))\n","        mod0 = base.clone(model).fit(x.loc[rows0, :], (y.loc[rows0]))\n","\n","        B = mod0.predict(x)\n","        S = mod1.predict(x) - B\n","\n","        if B.var()==0:\n","          B = B + np.random.normal(0, 0.1, nobs)\n","        if S.var()==0:\n","          S = S + np.random.normal(0, 0.1, nobs)\n","\n","        baseline[:, i] = B\n","        cate[:, i] = S\n","        ES = S.mean()\n","\n","        #Creating weights\n","        #p = treatment.mean()\n","        p=0.5\n","        num=main[main==1].shape[0]\n","\n","        weight=np.repeat((1/(p*(1-p))), num)\n","\n","################################################################################\n","\n","        ## BLP\n","        # assume P(treat|x) = P(treat) = mean(treat)\n","        p = treatment.mean()\n","        reg_df = pd.DataFrame(dict(\n","            y=y, B=B, treatment=treatment, S=S, main=main, excess_S=S-ES\n","        ))\n","        reg =smf.wls(\"y ~ B + S + I(treatment-p) + I((treatment-p)*(S-ES))\", data=reg_df.loc[main, :], weights = weight)\n","        #reg =smf.ols(\"y ~ B + I(treatment-p) + I((treatment-p)*(S-ES))\", data=reg_df.loc[main, :]);\n","        reg_fit = reg.fit(cov_type='cluster', cov_kwds={'groups': cluster_id[main] })\n","\n","        blp_se[i, :] = get_treatment_se(reg_fit, cluster_id, main)[3:]\n","        \n","        #beta1 BLP\n","        beta1_blp = reg_fit.params.iloc[3]\n","        beta1_blp_ci_l = reg_fit.conf_int(alpha=0.05, cols=None).iloc[:,0][3]\n","        beta1_blp_ci_u= reg_fit.conf_int(alpha=0.05, cols=None).iloc[:,1][3]\n","\n","        #beta2 BLP\n","        beta2_blp = reg_fit.params.iloc[4]\n","        beta2_blp_ci_l = reg_fit.conf_int(alpha=0.05, cols=None).iloc[:,0][4]\n","        beta2_blp_ci_u= reg_fit.conf_int(alpha=0.05, cols=None).iloc[:,1][4]\n","\n","        #beta1, beta2\n","        blp[i,:]=beta1_blp, beta2_blp\n","\n","        #BLP pvalue\n","        blp1_pvalue=reg_fit.pvalues[2]\n","        blp2_pvalue=reg_fit.pvalues[3]\n","\n","        blp1_1=(beta1_blp<0)*1*(blp1_pvalue/2) + (beta1_blp>0)*1*(1-blp1_pvalue/2)\n","        blp1_2=(beta1_blp<0)*1*(1-blp1_pvalue/2) + (beta1_blp>0)*1*(blp1_pvalue/2)\n","        #blp1=min(1, 4*min(blp1_1, blp1_2))\n","\n","        blp2_1=(beta2_blp<0)*1*(blp2_pvalue/2) + (beta2_blp>0)*1*(1-blp2_pvalue/2)\n","        blp2_2=(beta2_blp<0)*1*(1-blp2_pvalue/2) + (beta2_blp>0)*1*(blp2_pvalue/2)\n","        #blp2=min(1, 4*min(blp2_1, blp2_2))\n","\n","        blp_pvalue[i,:] = blp1_1, blp1_2, blp2_1, blp2_2\n","\n","        blp_ci_l[i,:]=beta1_blp_ci_l, beta2_blp_ci_l\n","        blp_ci_u[i,:]=beta1_blp_ci_u, beta2_blp_ci_u\n","\n","        lamb[i, 0] = reg_fit.params.iloc[-1]**2 * S.var()\n","\n","################################################################################\n","\n","        ## GATEs\n","        cutoffs = np.quantile(S, np.linspace(0,1, n_group + 1))\n","        cutoffs[-1] += 1\n","        for k in range(n_group):\n","            reg_df[f\"G{k}\"] = (cutoffs[k] <= S) & (S < cutoffs[k+1])\n","\n","        g_form = \"y ~ -1 + B + S + \" + \" + \".join([f\"I((treatment-p)*G{k})\" for k in range(n_group)])\n","        #g_form = \"y ~ B + S + \" + \" + \".join([f\"I((treatment-p)*G{k})\" for k in range(n_group)])\n","        g_reg = smf.wls(g_form, data=reg_df.loc[main, :], weights = weight)\n","        #g_reg = smf.ols(g_form, data=reg_df.loc[main, :])\n","        g_fit = g_reg.fit(cov_type='cluster', cov_kwds={'groups': cluster_id[main]})\n","        gate[i, :] = g_fit.params.values[2:] #g_fit.params.filter(regex=\"G\").values\n","\n","        lamb[i, 1] = (gate[i,:]**2).sum()/n_group\n","\n","################################################################################\n","\n","        ## Most/Least affected\n","        S2 = S + np.random.normal(0, 0.00001, len(S))\n","        cutoffs=np.quantile(S2, np.linspace(0,1, n_group + 1))\n","        cutoffs[0]=cutoffs[0] - 0.001\n","        cutoffs[5]=cutoffs[5] + 0.001 \n","\n","        for k in range(n_group):\n","          reg_df[f\"G{k}\"] = (cutoffs[k] <= S) & (S < cutoffs[k+1])\n","\n","        g_form = \"y ~ -1 + B + S + \" + \" + \".join([f\"I((treatment-p)*G{k})\" for k in range(n_group)])\n","        #g_form = \"y ~ -1 + I((treatment-p)*G4) + I((treatment-p)*G0)\" (right)\n","        #g_form = \"y ~ \" + \" + \".join([f\"I((treatment-p)*G{k})\" for k in range(n_group)])\n","        g_reg = smf.wls(g_form, data=reg_df.loc[main, :], weights = weight)\n","        g_fit = g_reg.fit(cov_type='cluster', cov_kwds={'groups': cluster_id[main]})\n","\n","        #Most affected \n","        most_coef=g_fit.params[6]        \n","        most_pvalue=g_fit.pvalues[6]\n","        most_ci_l=g_fit.conf_int(alpha=0.05, cols=None).iloc[6,0]\n","        most_ci_u=g_fit.conf_int(alpha=0.05, cols=None).iloc[6,1]\n","\n","\n","        #Least affected \n","        least_coef=g_fit.params[2]\n","        least_pvalue=g_fit.pvalues[2]\n","        least_ci_l=g_fit.conf_int(alpha=0.05, cols=None).iloc[2,0]\n","        least_ci_u=g_fit.conf_int(alpha=0.05, cols=None).iloc[2,1]\n","\n","        #Difference\n","        test=g_fit.t_test('I((treatment - p) * G4) - I((treatment - p) * G0) = 0')\n","        dir(test)\n","        #diff_coef= test.effect\n","        diff_coef=most_coef-least_coef\n","        diff_pvalue=test.pvalue\n","        diff_ci_l=test.conf_int(alpha=0.05)[0][0]\n","        diff_ci_u=test.conf_int(alpha=0.05)[0][1]\n","\n","        #pvalue\n","        most_p1=(most_coef<0)*1*(most_pvalue/2)+(most_coef>0)*1*(1-most_pvalue/2)\n","        most_p2=(most_coef<0)*1*(1-most_pvalue/2)+(most_coef>0)*1*(most_pvalue/2)\n","        least_p1=(least_coef<0)*1*(least_pvalue/2)+(least_coef>0)*1*(1-least_pvalue/2)\n","        least_p2=(least_coef<0)*1*(1-least_pvalue/2)+(least_coef>0)*1*(least_pvalue/2)\n","        diff_p1=(diff_coef<0)*1*(diff_pvalue/2)+(diff_coef>0)*1*(1-diff_pvalue/2)\n","        diff_p2=(diff_coef<0)*1*(1-diff_pvalue/2)+(diff_coef>0)*1*(diff_pvalue/2)\n","\n","        affected[i,:]=most_coef,least_coef,diff_coef\n","        affected_ci_l[i,:]=most_ci_l,least_ci_l,diff_ci_l\n","        affected_ci_u[i,:]=most_ci_u,least_ci_u,diff_ci_u\n","        affected_pvalue[i,:]=most_p1, most_p2, least_p1, least_p2, diff_p1, diff_p2\n","\n","################################################################################\n","\n","    blp_pvalue= np.nanmedian(blp_pvalue, axis=0)\n","    affected_pvalue= np.nanmedian(affected_pvalue, axis=0)\n","\n","    blp_new[0][0] = min(1, 4*min(blp_pvalue[0], blp_pvalue[1]))\n","    blp_new[0][1] = min(1, 4*min(blp_pvalue[2], blp_pvalue[3]))\n","    blp_pvalue = blp_new\n","\n","    affected_new[0][0] = min(1, 4*min(affected_pvalue[0], affected_pvalue[1]))\n","    affected_new[0][1] = min(1, 4*min(affected_pvalue[2], affected_pvalue[3]))\n","    affected_new[0][2] = min(1, 4*min(affected_pvalue[4], affected_pvalue[5]))\n","    affected_pvalue = affected_new\n","\n","\n","    out = dict(\n","        blp = blp,\n","        blp_ci_l=blp_ci_l, \n","        blp_ci_u=blp_ci_u,\n","        blp_pvalue=blp_pvalue, \n","        gate=gate,\n","        gate_se=gate_se, \n","        blp_se=blp_se,\n","        affected = affected,\n","        affected_ci_l =affected_ci_l, \n","        affected_ci_u= affected_ci_u, \n","        affected_pvalue = affected_pvalue,\n","        Lambda=lamb, \n","        baseline=baseline, \n","        cate=cate,\n","        name=type(model).__name__\n","    )\n","    return out"],"execution_count":105,"outputs":[]},{"cell_type":"code","metadata":{"id":"gou54f6yJcix","executionInfo":{"status":"ok","timestamp":1601378321297,"user_tz":-540,"elapsed":1224,"user":{"displayName":"Hazel Kang","photoUrl":"","userId":"09199737328986746816"}}},"source":["# Def of Generic ML summary\n","def generic_ml_summary(generic_ml_output):\n","    out = {\n","        x: np.nanmedian(generic_ml_output[x], axis=0)\n","        for x in [\"blp\", \"blp_ci_l\", \"blp_ci_u\", \"Lambda\", \"gate\",\n","                  \"affected\", \"affected_ci_l\", \"affected_ci_u\", \"gate_se\", \"blp_se\"]\n","    }\n","\n","    out.update({\"blp_pvalue\": generic_ml_output[\"blp_pvalue\"]})\n","    out.update({\"affected_pvalue\": generic_ml_output[\"affected_pvalue\"]})\n","\n","    out[\"name\"] = generic_ml_output[\"name\"]\n","    return out"],"execution_count":106,"outputs":[]},{"cell_type":"code","metadata":{"id":"gADcpC3WMXdn","executionInfo":{"status":"ok","timestamp":1601378321299,"user_tz":-540,"elapsed":1183,"user":{"displayName":"Hazel Kang","photoUrl":"","userId":"09199737328986746816"}}},"source":["#Step 1: Tune ML hyperparameters\n","import xgboost as xgb\n","models = [\n","    linear_model.ElasticNetCV(cv=5, n_alphas=25, max_iter=1000, tol=1e-3, n_jobs=-1, l1_ratio=0.9),\n","    ensemble.RandomForestRegressor(n_estimators=100, min_samples_leaf=20),\n","    xgb.XGBRegressor(n_estimators=100, max_depth=3, reg_lambda=2.0, reg_alpha=0.0, objective=\"reg:squarederror\"),\n","    neural_network.MLPRegressor(hidden_layer_sizes=(100,), max_iter=1000, activation=\"relu\", solver=\"adam\", tol=1e-3, early_stopping=True, alpha=0.0001, learning_rate=\"constant\", shuffle=True)\n","]\n","\n","#Set parameters\n","x=Xl\n","treatment=treatment\n","n_split= 100\n","cluster_id=loc_id\n","\n","#Tune parameters\n","y=satisfaction1\n","n_group=5"],"execution_count":107,"outputs":[]},{"cell_type":"code","metadata":{"id":"cAuHHUOaHXpi","executionInfo":{"status":"ok","timestamp":1601379099410,"user_tz":-540,"elapsed":779277,"user":{"displayName":"Hazel Kang","photoUrl":"","userId":"09199737328986746816"}},"outputId":"00a67fe1-8a5d-4280-f1eb-55c1611ca0fa","colab":{"base_uri":"https://localhost:8080/","height":88}},"source":["##Step 1: Best BLP / GATES - choose best ML method\n","##Best BLP \n","model_a=models[0]\n","model_b=models[1]\n","model_c=models[2]\n","model_d=models[3]\n","\n","result1=generic_ml_model(x, y, treatment, model_a, n_split, n_group, cluster_id=loc_id)\n","ElasticNet_BestBLP=generic_ml_summary(result1)[\"Lambda\"][0]\n","\n","result2=generic_ml_model(x, y, treatment, model_b, n_split, n_group, cluster_id=loc_id)\n","RandomForest_BestBLP=generic_ml_summary(result2)[\"Lambda\"][0]\n","\n","result3=generic_ml_model(x, y, treatment, model_c, n_split, n_group, cluster_id=loc_id)\n","Booster_BestBLP=generic_ml_summary(result3)[\"Lambda\"][0]\n","\n","result4=generic_ml_model(x, y, treatment, model_d, n_split, n_group, cluster_id=loc_id)\n","neural_network_BestBLP=generic_ml_summary(result4)[\"Lambda\"][0]\n","\n","print (ElasticNet_BestBLP, RandomForest_BestBLP, Booster_BestBLP, neural_network_BestBLP)\n","#Boosting/Random Forest Best\n","\n","##p value##\n","blp_pvalue1=result1[\"blp_pvalue\"]\n","blp_pvalue2=result2[\"blp_pvalue\"]\n","blp_pvalue3=result3[\"blp_pvalue\"]\n","blp_pvalue4=result4[\"blp_pvalue\"]\n","\n","affected_pvalue1=result1[\"affected_pvalue\"]\n","affected_pvalue2=result2[\"affected_pvalue\"]\n","affected_pvalue3=result3[\"affected_pvalue\"]\n","affected_pvalue4=result4[\"affected_pvalue\"]\n","\n","\n","##Best GATE\n","ElasticNet_BestGATE=generic_ml_summary(result1)[\"Lambda\"][1]\n","RandomForest_BestGATE=generic_ml_summary(result2)[\"Lambda\"][1]\n","Booster_BestGATE=generic_ml_summary(result3)[\"Lambda\"][1]\n","neural_network_BestGATE=generic_ml_summary(result4)[\"Lambda\"][1]\n","\n","#Stage 1: Create Table\n","\n","best = {'Elastic Net':  [ElasticNet_BestBLP, ElasticNet_BestGATE],\n","        'Boosting': [Booster_BestBLP, Booster_BestGATE],\n","        'Neural Network': [neural_network_BestBLP, neural_network_BestGATE],\n","        'Random Forest': [RandomForest_BestBLP, RandomForest_BestGATE]\n","        }\n","\n","Best_df = pd.DataFrame (best, columns = ['Elastic Net','Boosting','Neural Network','Random Forest'], index=['Best BLP','Best GATES'])\n","print(Best_df)\n","\n","Best_df.to_csv(\"/content/drive/My Drive/ML/new2/Stage1_Comparison_satisfaction1.csv\", index=True, header=True)\n"],"execution_count":108,"outputs":[{"output_type":"stream","text":["0.0011502344033280255 0.006678230275293941 0.009893323049381574 0.00451446257378805\n","            Elastic Net  Boosting  Neural Network  Random Forest\n","Best BLP       0.001150  0.009893        0.004514       0.006678\n","Best GATES     0.011488  0.017132        0.011709       0.012700\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"T9hsdUU9ziuh","executionInfo":{"status":"ok","timestamp":1601379099423,"user_tz":-540,"elapsed":779254,"user":{"displayName":"Hazel Kang","photoUrl":"","userId":"09199737328986746816"}},"outputId":"4d196791-9a67-4429-99fc-eeb7667587c5","colab":{"base_uri":"https://localhost:8080/","height":481}},"source":["##Choose the best 2 ML methods\n","\n","#Empty list\n","model_blp_final=[0,0]\n","model_gate_final=[0,0]\n","\n","#BLP\n","blp_ml=[ElasticNet_BestBLP, RandomForest_BestBLP, Booster_BestBLP, neural_network_BestBLP]\n","\n","# Choose Best BLP\n","if max(blp_ml)==ElasticNet_BestBLP:\n","  model_blp_final[0]=models[0]\n","elif max(blp_ml)== RandomForest_BestBLP:\n","  model_blp_final[0]=models[1]\n","elif max(blp_ml)== Booster_BestBLP:\n","  model_blp_final[0]=models[2]\n","else:\n","  model_blp_final[0]=models[3]\n","\n","import heapq\n","if heapq.nlargest(2, blp_ml)[1]==ElasticNet_BestBLP:\n","  model_blp_final[1]=models[0]\n","elif heapq.nlargest(2, blp_ml)[1]== RandomForest_BestBLP:\n","  model_blp_final[1]=models[1]\n","elif heapq.nlargest(2, blp_ml)[1]== Booster_BestBLP:\n","  model_blp_final[1]=models[2]\n","else:\n","  model_blp_final[1]=models[3]\n","\n","#GATE\n","gate_ml=[ElasticNet_BestGATE, RandomForest_BestGATE, Booster_BestGATE, neural_network_BestGATE]\n","\n","#Choose Best GATE\n","if max(gate_ml)==ElasticNet_BestGATE:\n","  model_gate_final[0]=models[0]\n","elif max(gate_ml)== RandomForest_BestGATE:\n","  model_gate_final[0]=models[1]\n","elif max(gate_ml)== Booster_BestGATE:\n","  model_gate_final[0]=models[2]\n","else:\n","  model_gate_final[0]=models[3]\n","\n","import heapq\n","if heapq.nlargest(2, gate_ml)[1]==ElasticNet_BestGATE:\n","  model_gate_final[1]=models[0]\n","elif heapq.nlargest(2, gate_ml)[1]== RandomForest_BestGATE:\n","  model_gate_final[1]=models[1]\n","elif heapq.nlargest(2, gate_ml)[1]== Booster_BestGATE:\n","  model_gate_final[1]=models[2]\n","else:\n","  model_gate_final[1]=models[3]\n","\n","#Change orders \n","#model_blp_final[0], model_blp_final[1] = model_blp_final[1], model_blp_final[0]\n","#model_gate_final[0], model_gate_final[1] = model_gate_final[1], model_gate_final[0]\n","\n","print(model_blp_final,model_gate_final)\n","\n","assert model_blp_final==model_gate_final"],"execution_count":109,"outputs":[{"output_type":"stream","text":["[XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n","             colsample_bynode=1, colsample_bytree=1, gamma=0,\n","             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n","             max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n","             n_jobs=1, nthread=None, objective='reg:squarederror',\n","             random_state=0, reg_alpha=0.0, reg_lambda=2.0, scale_pos_weight=1,\n","             seed=None, silent=None, subsample=1, verbosity=1), RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n","                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n","                      max_samples=None, min_impurity_decrease=0.0,\n","                      min_impurity_split=None, min_samples_leaf=20,\n","                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n","                      n_estimators=100, n_jobs=None, oob_score=False,\n","                      random_state=None, verbose=0, warm_start=False)] [XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n","             colsample_bynode=1, colsample_bytree=1, gamma=0,\n","             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n","             max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n","             n_jobs=1, nthread=None, objective='reg:squarederror',\n","             random_state=0, reg_alpha=0.0, reg_lambda=2.0, scale_pos_weight=1,\n","             seed=None, silent=None, subsample=1, verbosity=1), RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n","                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n","                      max_samples=None, min_impurity_decrease=0.0,\n","                      min_impurity_split=None, min_samples_leaf=20,\n","                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n","                      n_estimators=100, n_jobs=None, oob_score=False,\n","                      random_state=None, verbose=0, warm_start=False)]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BPYKF9uuiHk6","executionInfo":{"status":"ok","timestamp":1601379379038,"user_tz":-540,"elapsed":1058842,"user":{"displayName":"Hazel Kang","photoUrl":"","userId":"09199737328986746816"}},"outputId":"f579b606-61a0-4a6c-8308-b69ecef8ea18","colab":{"base_uri":"https://localhost:8080/","height":771}},"source":["## Stage 2 : BLP & GATE of CATE\n","#Def of reporting results \n","\n","kw = dict(x=x, treatment= treatment, n_split=n_split, n_group=n_group, cluster_id=cluster_id)\n","@ignore_warnings(category=ConvergenceWarning)\n","\n","\n","def evaluate_models(models, y, **other_kw):\n","    all_kw = kw.copy()\n","    all_kw[\"y\"] = y\n","    all_kw.update(other_kw)\n","    return list(map(lambda x: generic_ml_model(model=x, **all_kw), models))\n","\n","\n","def generate_report(results):\n","    summaries = list(map(generic_ml_summary, results))\n","    df_plot = pd.DataFrame({\n","        mod[\"name\"]: np.median(mod[\"cate\"], axis=1)\n","        for mod in results\n","    })\n","\n","    print(\"\\n\\nBest linear projection of CATE\")\n","    df_cate = pd.concat({\n","        s[\"name\"]: pd.DataFrame(dict(blp=s[\"blp\"], se=s[\"blp_se\"], lower=s[\"blp_ci_l\"], upper=s[\"blp_ci_u\"]))\n","        for s in summaries\n","    }).T.stack()\n","    display(df_cate)\n","    df_cate.to_csv(\"/content/drive/My Drive/ML/new2/Stage2_BLP_satisfaction1.csv\", index=True, header=True)\n","\n","    print(\"\\n\\nGroup average treatment effects:\")\n","    df_groups = pd.concat({\n","        s[\"name\"]: pd.DataFrame(dict(gate=s[\"affected\"], se=s[\"gate_se\"], lower=s[\"affected_ci_l\"], upper=s[\"affected_ci_u\"]))\n","        for s in summaries\n","    }).T.stack()\n","    display(df_groups)\n","    df_groups.to_csv(\"/content/drive/My Drive/ML/new2/Stage2_gate_satisfaction1.csv\", index=True, header=True)\n","\n","#Only 2 Best ML method\n","\n","results = evaluate_models(models=model_blp_final, y=y)\n","generate_report(results)"],"execution_count":110,"outputs":[{"output_type":"stream","text":["\n","\n","Best linear projection of CATE\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th></th>\n","      <th>XGBRegressor</th>\n","      <th>RandomForestRegressor</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">blp</th>\n","      <th>0</th>\n","      <td>-0.080047</td>\n","      <td>-0.078379</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.660449</td>\n","      <td>0.444939</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">se</th>\n","      <th>0</th>\n","      <td>0.017106</td>\n","      <td>0.016566</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.099868</td>\n","      <td>0.084099</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">lower</th>\n","      <th>0</th>\n","      <td>-0.115114</td>\n","      <td>-0.111040</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.453741</td>\n","      <td>0.282355</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">upper</th>\n","      <th>0</th>\n","      <td>-0.046560</td>\n","      <td>-0.045539</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.849959</td>\n","      <td>0.617569</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         XGBRegressor  RandomForestRegressor\n","blp   0     -0.080047              -0.078379\n","      1      0.660449               0.444939\n","se    0      0.017106               0.016566\n","      1      0.099868               0.084099\n","lower 0     -0.115114              -0.111040\n","      1      0.453741               0.282355\n","upper 0     -0.046560              -0.045539\n","      1      0.849959               0.617569"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","\n","Group average treatment effects:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th></th>\n","      <th>XGBRegressor</th>\n","      <th>RandomForestRegressor</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"3\" valign=\"top\">gate</th>\n","      <th>0</th>\n","      <td>0.057881</td>\n","      <td>0.018675</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.227709</td>\n","      <td>-0.194208</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.288707</td>\n","      <td>0.204645</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"3\" valign=\"top\">se</th>\n","      <th>0</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"3\" valign=\"top\">lower</th>\n","      <th>0</th>\n","      <td>-0.008282</td>\n","      <td>-0.046088</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.294270</td>\n","      <td>-0.261629</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.193615</td>\n","      <td>0.115500</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"3\" valign=\"top\">upper</th>\n","      <th>0</th>\n","      <td>0.124010</td>\n","      <td>0.081680</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.165116</td>\n","      <td>-0.126828</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.379203</td>\n","      <td>0.301151</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         XGBRegressor  RandomForestRegressor\n","gate  0      0.057881               0.018675\n","      1     -0.227709              -0.194208\n","      2      0.288707               0.204645\n","se    0      0.000000               0.000000\n","      1      0.000000               0.000000\n","      2      0.000000               0.000000\n","lower 0     -0.008282              -0.046088\n","      1     -0.294270              -0.261629\n","      2      0.193615               0.115500\n","upper 0      0.124010               0.081680\n","      1     -0.165116              -0.126828\n","      2      0.379203               0.301151"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"ByaxaU4B9EcL","executionInfo":{"status":"ok","timestamp":1601379379040,"user_tz":-540,"elapsed":1058814,"user":{"displayName":"Hazel Kang","photoUrl":"","userId":"09199737328986746816"}},"outputId":"a08897e6-d02f-4497-ff76-9a9243404ae6","colab":{"base_uri":"https://localhost:8080/","height":88}},"source":["# Stage 2: Create Table of BLP -BLP\n","#BLP\n","blp_path=\"/content/drive/My Drive/ML/new2/Stage2_BLP_satisfaction1.csv\"\n","blp=pd.read_csv(blp_path)\n","\n","#Rename ML methods\n","if blp.columns[2]=='ElasticNetCV':\n","  blp.rename(columns={'ElasticNetCV':'Elastic Net'}, inplace=True)\n","elif blp.columns[2]=='MLPRegressor':\n","  blp.rename(columns={'MLPRegressor':'Neural Network'}, inplace=True)\n","elif blp.columns[2]=='RandomForestRegressor':\n","  blp.rename(columns={'RandomForestRegressor':'Random Forest'}, inplace=True)\n","else:\n","  blp.rename(columns={'XGBRegressor':'Booster'}, inplace=True)\n","\n","if blp.columns[3]=='ElasticNetCV':\n","  blp.rename(columns={'ElasticNetCV':'Elastic Net'}, inplace=True)\n","elif blp.columns[3]=='MLPRegressor':\n","  blp.rename(columns={'MLPRegressor':'Neural Network'}, inplace=True)\n","elif blp.columns[3]=='RandomForestRegressor':\n","  blp.rename(columns={'RandomForestRegressor':'Random Forest'}, inplace=True)\n","else:\n","  blp.rename(columns={'XGBRegressor':'Booster'}, inplace=True)\n","\n","#Create Dataframe\n","a = np.arange(12).reshape(3,4)\n","a_df=pd.DataFrame(a)\n","\n","#1st row: BLP\n","a_df.iloc[0,0]=round(blp.iloc[0,2],4)\n","a_df.iloc[0,1]=round(blp.iloc[1,2],4)\n","a_df.iloc[0,2]=round(blp.iloc[0,3],4)\n","a_df.iloc[0,3]=round(blp.iloc[1,3],4)\n","\n","#2nd row: CI\n","\n","a_df.iloc[1,0]=f\"({round(blp.iloc[4,2],4)},{round(blp.iloc[6,2],4)})\"\n","a_df.iloc[1,1]=f\"({round(blp.iloc[5,2],4)},{round(blp.iloc[7,2],4)})\"\n","a_df.iloc[1,2]=f\"({round(blp.iloc[4,3],4)},{round(blp.iloc[6,3],4)})\"\n","a_df.iloc[1,3]=f\"({round(blp.iloc[5,3],4)},{round(blp.iloc[7,3],4)})\"\n","\n","#3rd row: SE \n","a_df.iloc[2,0]=f\"[{round(blp.iloc[2,2],4)}]\"\n","a_df.iloc[2,1]=f\"[{round(blp.iloc[3,2],4)}]\"\n","a_df.iloc[2,2]=f\"[{round(blp.iloc[2,3],4)}]\"\n","a_df.iloc[2,3]=f\"[{round(blp.iloc[3,3],4)}]\"\n","\n","a_df.rename(columns={0:f\"{blp.columns[2]} ATE\", 1:f\"{blp.columns[2]} HET\", 2:f\"{blp.columns[3]} ATE\",3:f\"{blp.columns[3]} HET\" },inplace=True)\n","\n","print(a_df)\n","a_df.to_csv(\"/content/drive/My Drive/ML/new2/Stage2_BLP_satisfaction1.csv\", index=False, header=True)\n","\n","#blp_data = pd.DataFrame(columns=['ATE(beta1)', 'HET(beta2)', 'ATE(beta1)', 'HET(beta2)'], index=False)\n","#blp_data\n","#GATES"],"execution_count":111,"outputs":[{"output_type":"stream","text":["         Booster ATE    Booster HET Random Forest ATE Random Forest HET\n","0              -0.08         0.6604           -0.0784            0.4449\n","1  (-0.1151,-0.0466)  (0.4537,0.85)  (-0.111,-0.0455)   (0.2824,0.6176)\n","2           [0.0171]       [0.0999]          [0.0166]          [0.0841]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Enqm2qmg-WTQ","executionInfo":{"status":"ok","timestamp":1601379379042,"user_tz":-540,"elapsed":1058801,"user":{"displayName":"Hazel Kang","photoUrl":"","userId":"09199737328986746816"}},"outputId":"e898444d-620f-4256-e872-0070158d5eae","colab":{"base_uri":"https://localhost:8080/","height":88}},"source":["#BLP - pvalue substitution\n","if a_df.columns[0]== 'Elastic Net ATE':\n","  a_df.iloc[2,0]='[{:.4f}]'.format(blp_pvalue1[0][0])\n","  a_df.iloc[2,1]='[{:.4f}]'.format(blp_pvalue1[0][1])\n","elif a_df.columns[0]== 'Random Forest ATE':\n","  a_df.iloc[2,0]='[{:.4f}]'.format(blp_pvalue2[0][0])\n","  a_df.iloc[2,1]='[{:.4f}]'.format(blp_pvalue2[0][1])\n","elif a_df.columns[0]== 'Booster ATE':\n","  a_df.iloc[2,0]='[{:.4f}]'.format(blp_pvalue3[0][0])\n","  a_df.iloc[2,1]='[{:.4f}]'.format(blp_pvalue3[0][1])\n","else: \n","  a_df.iloc[2,0]='[{:.4f}]'.format(blp_pvalue4[0][0])\n","  a_df.iloc[2,1]='[{:.4f}]'.format(blp_pvalue4[0][1])\n","\n","\n","if a_df.columns[2]== 'Elastic Net HET':\n","  a_df.iloc[2,2]='[{:.4f}]'.format(blp_pvalue1[0][0])\n","  a_df.iloc[2,3]='[{:.4f}]'.format(blp_pvalue1[0][1])\n","elif a_df.columns[2]== 'Random Forest HET':\n","  a_df.iloc[2,2]='[{:.4f}]'.format(blp_pvalue2[0][0])\n","  a_df.iloc[2,3]='[{:.4f}]'.format(blp_pvalue2[0][1])\n","elif a_df.columns[2]== 'Booster HET':\n","  a_df.iloc[2,2]='[{:.4f}]'.format(blp_pvalue3[0][0])\n","  a_df.iloc[2,3]='[{:.4f}]'.format(blp_pvalue3[0][1])\n","else: \n","  a_df.iloc[2,2]='[{:.4f}]'.format(blp_pvalue4[0][0])\n","  a_df.iloc[2,3]='[{:.4f}]'.format(blp_pvalue4[0][1])\n","\n","\n","print(a_df)\n","\n","a_df.to_csv(\"/content/drive/My Drive/ML/new2/Stage2_BLP_satisfaction1.csv\", index=False, header=True)"],"execution_count":112,"outputs":[{"output_type":"stream","text":["         Booster ATE    Booster HET Random Forest ATE Random Forest HET\n","0              -0.08         0.6604           -0.0784            0.4449\n","1  (-0.1151,-0.0466)  (0.4537,0.85)  (-0.111,-0.0455)   (0.2824,0.6176)\n","2           [0.0000]       [0.0000]          [0.1138]          [0.0001]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VpkeZiAdeGhU","executionInfo":{"status":"ok","timestamp":1601379379043,"user_tz":-540,"elapsed":1058787,"user":{"displayName":"Hazel Kang","photoUrl":"","userId":"09199737328986746816"}},"outputId":"7410785f-fb7f-4496-8193-f95a56d00bfe","colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["# Stage 2: Create Table of GATE\n","#BLP\n","gate_path=\"/content/drive/My Drive/ML/new2/Stage2_gate_satisfaction1.csv\"\n","gate=pd.read_csv(gate_path)\n","\n","#Rename ML methods\n","if gate.columns[2]=='ElasticNetCV':\n","  gate.rename(columns={'ElasticNetCV':'Elastic Net'}, inplace=True)\n","elif gate.columns[2]=='MLPRegressor':\n","  gate.rename(columns={'MLPRegressor':'Neural Network'}, inplace=True)\n","elif gate.columns[2]=='RandomForestRegressor':\n","  gate.rename(columns={'RandomForestRegressor':'Random Forest'}, inplace=True)\n","else:\n","  gate.rename(columns={'XGBRegressor':'Booster'}, inplace=True)\n","\n","if gate.columns[3]=='ElasticNetCV':\n","  gate.rename(columns={'ElasticNetCV':'Elastic Net'}, inplace=True)\n","elif gate.columns[3]=='MLPRegressor':\n","  gate.rename(columns={'MLPRegressor':'Neural Network'}, inplace=True)\n","elif gate.columns[3]=='RandomForestRegressor':\n","  gate.rename(columns={'RandomForestRegressor':'Random Forest'}, inplace=True)\n","else:\n","  gate.rename(columns={'XGBRegressor':'Booster'}, inplace=True)\n","\n","#Create Dataframe\n","b = np.arange(18).reshape(3,6)\n","b_df=pd.DataFrame(b)\n","\n","#1st row: gate\n","b_df.iloc[0,0]=round(gate.iloc[0,2],4)\n","b_df.iloc[0,1]=round(gate.iloc[1,2],4)\n","b_df.iloc[0,2]=round(gate.iloc[2,2],4)\n","b_df.iloc[0,3]=round(gate.iloc[0,3],4)\n","b_df.iloc[0,4]=round(gate.iloc[1,3],4)\n","b_df.iloc[0,5]=round(gate.iloc[2,3],4)\n","\n","#2nd row: CI\n","b_df.iloc[1,0]=f\"({round(gate.iloc[6,2],4)},{round(gate.iloc[9,2],4)})\"\n","b_df.iloc[1,1]=f\"({round(gate.iloc[7,2],4)},{round(gate.iloc[10,2],4)})\"\n","b_df.iloc[1,2]=f\"({round(gate.iloc[8,2],4)},{round(gate.iloc[11,2],4)})\"\n","b_df.iloc[1,3]=f\"({round(gate.iloc[6,3],4)},{round(gate.iloc[9,3],4)})\"\n","b_df.iloc[1,4]=f\"({round(gate.iloc[7,3],4)},{round(gate.iloc[10,3],4)})\"\n","b_df.iloc[1,5]=f\"({round(gate.iloc[8,3],4)},{round(gate.iloc[11,3],4)})\"\n","\n","#3rd row: se\n","b_df.iloc[2,0]=f\"[{round(gate.iloc[3,2],4)}]\"\n","b_df.iloc[2,1]=f\"[{round(gate.iloc[4,2],4)}]\"\n","b_df.iloc[2,2]=f\"[{round(gate.iloc[5,2],4)}]\"\n","b_df.iloc[2,3]=f\"[{round(gate.iloc[3,3],4)}]\"\n","b_df.iloc[2,4]=f\"[{round(gate.iloc[4,3],4)}]\"\n","b_df.iloc[2,5]=f\"[{round(gate.iloc[5,3],4)}]\"\n","\n","b_df.rename(columns={0:f\"{gate.columns[2]} 20% Most\", 1:f\"{gate.columns[2]} 20% Least\", 2:f\"{gate.columns[2]} Difference\", 3:f\"{gate.columns[3]} 20% Most\", 4:f\"{gate.columns[3]} 20% Least\", 5:f\"{gate.columns[3]} Difference\"},inplace=True)\n","\n","print(b_df)\n","b_df.to_csv(\"/content/drive/My Drive/ML/new2/Stage2_gate_satisfaction1.csv\", index=False, header=True)\n","\n"],"execution_count":113,"outputs":[{"output_type":"stream","text":["  Booster 20% Most  ... Random Forest Difference\n","0           0.0579  ...                   0.2046\n","1  (-0.0083,0.124)  ...          (0.1155,0.3012)\n","2            [0.0]  ...                    [0.0]\n","\n","[3 rows x 6 columns]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"10ADUkeqDndz","executionInfo":{"status":"ok","timestamp":1601379379045,"user_tz":-540,"elapsed":1058774,"user":{"displayName":"Hazel Kang","photoUrl":"","userId":"09199737328986746816"}},"outputId":"8fc85fab-1a29-4e4e-f75e-5acc279c2edd","colab":{"base_uri":"https://localhost:8080/","height":144}},"source":["#GATES p value substitution\n","if b_df.columns[0]== 'Elastic Net 20% Most':\n","  b_df.iloc[2,0]='[{:.4f}]'.format(affected_pvalue1[0][0])\n","  b_df.iloc[2,1]='[{:.4f}]'.format(affected_pvalue1[0][1])\n","  b_df.iloc[2,2]='[{:.4f}]'.format(affected_pvalue1[0][2])\n","elif b_df.columns[0]== 'Random Forest 20% Most':\n","  b_df.iloc[2,0]='[{:.4f}]'.format(affected_pvalue2[0][0])\n","  b_df.iloc[2,1]='[{:.4f}]'.format(affected_pvalue2[0][1])\n","  b_df.iloc[2,2]='[{:.4f}]'.format(affected_pvalue2[0][2])\n","elif b_df.columns[0]== 'Booster 20% Most':\n","  b_df.iloc[2,0]='[{:.4f}]'.format(affected_pvalue3[0][0])\n","  b_df.iloc[2,1]='[{:.4f}]'.format(affected_pvalue3[0][1])\n","  b_df.iloc[2,2]='[{:.4f}]'.format(affected_pvalue3[0][2])\n","else: \n","  b_df.iloc[2,0]='[{:.4f}]'.format(affected_pvalue4[0][0])\n","  b_df.iloc[2,1]='[{:.4f}]'.format(affected_pvalue4[0][1])\n","  b_df.iloc[2,2]='[{:.4f}]'.format(affected_pvalue4[0][2])\n","\n","\n","if b_df.columns[3]== 'Elastic Net 20% Most':\n","  b_df.iloc[2,3]='[{:.4f}]'.format(affected_pvalue1[0][0])\n","  b_df.iloc[2,4]='[{:.4f}]'.format(affected_pvalue1[0][1])\n","  b_df.iloc[2,5]='[{:.4f}]'.format(affected_pvalue1[0][2])\n","elif b_df.columns[3]== 'Random Forest 20% Most':\n","  b_df.iloc[2,3]='[{:.4f}]'.format(affected_pvalue2[0][0])\n","  b_df.iloc[2,4]='[{:.4f}]'.format(affected_pvalue2[0][1])\n","  b_df.iloc[2,5]='[{:.4f}]'.format(affected_pvalue2[0][2])\n","elif b_df.columns[3]== 'Booster 20% Most':\n","  b_df.iloc[2,3]='[{:.4f}]'.format(affected_pvalue3[0][0])\n","  b_df.iloc[2,4]='[{:.4f}]'.format(affected_pvalue3[0][1])\n","  b_df.iloc[2,5]='[{:.4f}]'.format(affected_pvalue3[0][2])\n","else: \n","  b_df.iloc[2,3]='[{:.4f}]'.format(affected_pvalue4[0][0])\n","  b_df.iloc[2,4]='[{:.4f}]'.format(affected_pvalue4[0][1])\n","  b_df.iloc[2,5]='[{:.4f}]'.format(affected_pvalue4[0][2])\n","\n","\n","\n","print(b_df, affected_pvalue1, affected_pvalue2, affected_pvalue3, affected_pvalue4)\n","\n","b_df.to_csv(\"/content/drive/My Drive/ML/new2/Stage2_gate_satisfaction1.csv\", index=False, header=True)\n"],"execution_count":114,"outputs":[{"output_type":"stream","text":["  Booster 20% Most  ... Random Forest Difference\n","0           0.0579  ...                   0.2046\n","1  (-0.0083,0.124)  ...          (0.1155,0.3012)\n","2         [0.1928]  ...                 [0.0000]\n","\n","[3 rows x 6 columns] [[0.45116978 0.00100369 0.17239502]] [[1.00000000e+00 3.20186540e-08 1.14305318e-05]] [[1.92762476e-01 3.40850298e-11 5.20053013e-09]] [[1.00000000e+00 1.15084645e-06 1.81083188e-03]]\n"],"name":"stdout"}]}]}
